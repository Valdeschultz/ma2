{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Bag-of-Words Model\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/bow_guide.ipynb](guides/bow_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: Are there any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `bow_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "# imports for the project\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vald0\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 2) (7600, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 2), (760, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "    \"\"\" Preprocess the dataset \n",
    "\n",
    "    Operations:\n",
    "    - Map the label to the corresponding category\n",
    "    - Filter out the labels not in the label_map\n",
    "    - Sample a fraction of the dataset (stratified by label)\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataset to preprocess\n",
    "    - frac (float): The fraction of the dataset to sample in each category\n",
    "    - label_map (dict): A mapping of the original label to the new label\n",
    "    - seed (int): The random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The preprocessed dataset\n",
    "    \"\"\"\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "del train\n",
    "del test\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960,) (240,) (960,) (240,)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    \n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test\n",
    "\n",
    ") = train_test_split(train_df[\"text\"], train_df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting the models and finetuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Initialize the CountVectorizer (Bag of Words model)\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model_lr = LogisticRegression(max_iter=200)\n",
    "model_lr.fit(X_train_vec, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test_vec)\n",
    "\n",
    "# Naive Bayes Model\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_vec, y_train)\n",
    "y_pred_nb = model_nb.predict(X_test_vec)\n",
    "\n",
    "# Hyperparameter Tuning for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "    , 'penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=200), param_grid_lr, cv=3, verbose=2)\n",
    "grid_search_lr.fit(X_train_vec, y_train)\n",
    "\n",
    "# Hyperparameter Tuning for Naive Bayes\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.01, 0.1, 1, 2, 3, 10],\n",
    "    'fit_prior': [True, False]\n",
    "    , 'force_alpha': [True, False]\n",
    "}\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=3, verbose=2)\n",
    "grid_search_nb.fit(X_train_vec, y_train)\n",
    "\n",
    "\n",
    "# Print the best estimators for each model\n",
    "print(\"Best Logistic Regression Estimator:\", grid_search_lr.best_estimator_)\n",
    "print(\"Best Naive Bayes Estimator:\", grid_search_nb.best_estimator_)\n",
    "\n",
    "# Evaluate models before GridSearch\n",
    "print(\"Classification Report for Logistic Regression (Before GridSearch):\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Classification Report for Naive Bayes (Before GridSearch):\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Evaluate models after GridSearch\n",
    "best_model_lr = grid_search_lr.best_estimator_\n",
    "best_model_nb = grid_search_nb.best_estimator_\n",
    "\n",
    "# Predict using the best models\n",
    "y_pred_lr_best = best_model_lr.predict(X_test_vec)\n",
    "y_pred_nb_best = best_model_nb.predict(X_test_vec)\n",
    "\n",
    "print(\"Classification Report for Logistic Regression (After GridSearch):\")\n",
    "print(classification_report(y_test, y_pred_lr_best))\n",
    "\n",
    "print(\"Classification Report for Naive Bayes (After GridSearch):\")\n",
    "print(classification_report(y_test, y_pred_nb_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reflections\n",
    "For output we get:\n",
    "Best Logistic Regression Estimator: LogisticRegression(C=0.1, max_iter=200)\n",
    "Best Naive Bayes Estimator: MultinomialNB(alpha=1, fit_prior=False)\n",
    "\n",
    "Classification Report for Logistic Regression (Before GridSearch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Business       0.78      0.68      0.72        62\n",
    "    Sci/Tech       0.77      0.67      0.71        60\n",
    "      Sports       0.80      0.88      0.84        60\n",
    "       World       0.74      0.86      0.79        58\n",
    "\n",
    "    accuracy                           0.77       240\n",
    "   macro avg       0.77      0.77      0.77       240\n",
    "weighted avg       0.77      0.77      0.77       240\n",
    "\n",
    "\n",
    "Classification Report for Logistic Regression (After GridSearch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Business       0.78      0.65      0.71        62\n",
    "    Sci/Tech       0.72      0.65      0.68        60\n",
    "      Sports       0.76      0.87      0.81        60\n",
    "       World       0.76      0.88      0.82        58\n",
    "\n",
    "    accuracy                           0.76       240\n",
    "   macro avg       0.76      0.76      0.76       240\n",
    "weighted avg       0.76      0.76      0.75       240\n",
    "\n",
    "Classification Report for Naive Bayes (Before GridSearch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Business       0.79      0.84      0.81        62\n",
    "    Sci/Tech       0.88      0.63      0.74        60\n",
    "      Sports       0.87      0.88      0.88        60\n",
    "       World       0.74      0.90      0.81        58\n",
    "\n",
    "    accuracy                           0.81       240\n",
    "   macro avg       0.82      0.81      0.81       240\n",
    "weighted avg       0.82      0.81      0.81       240\n",
    "\n",
    "Classification Report for Naive Bayes (After GridSearch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Business       0.79      0.84      0.81        62\n",
    "    Sci/Tech       0.88      0.63      0.74        60\n",
    "      Sports       0.87      0.88      0.88        60\n",
    "       World       0.74      0.90      0.81        58\n",
    "\n",
    "    accuracy                           0.81       240\n",
    "   macro avg       0.82      0.81      0.81       240\n",
    "weighted avg       0.82      0.81      0.81       240\n",
    "\n",
    "The performance of the system indicates that the Naive Bayes classifier outperforms Logistic Regression in terms of accuracy and f1-score, both before and after hyperparameter tuning. The hyperparameter tuning for Logistic Regression did not significantly improve its performance, suggesting that the default parameters were already close to optimal for this dataset. For Naive Bayes, the best parameters (alpha=1, fit_prior=False) did not change the performance of the model at all. from the data it seems The Bag-of-Words model, captures enough information to achieve reasonable classification performance, but more sophisticated models like an LLM or word embeddings could potentially yield better results which will be explored in the next tasks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
